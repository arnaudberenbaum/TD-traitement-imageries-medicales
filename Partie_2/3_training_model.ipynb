{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net model\n",
    "In the following notebook, you'll be using a network architecture called \"U-Net\". The name of this network architecture comes from it's U-like shape when shown in a diagram like this (image from [ResearchGate](https://www.researchgate.net/figure/The-architecture-of-the-standard-3D-U-Net-The-network-takes-a-3D-patch-cuboid-and_fig2_353490938)) : \n",
    "\n",
    "<img src=\"../assets/unet.png\" alt=\"U-net network\" width=\"600\"/>\n",
    "\n",
    "U-nets are commonly used for image segmentation. \n",
    "\n",
    "As you can see from the figure, this architecture features a series of down-convolutions connected by max-pooling operations (the \"encoder\", used to capture important features from the image) followed by a series of up-convolutions connected by upsampling and concatenation operations (the \"decoder\", used to predict the segmentation mask). Each of the down-convolutions is also connected directly to the concatenation operations in the upsampling portion of the network. For more detail on the U-Net architecture, have a look at the original [U-Net paper by Ronneberger et al. 2015](https://arxiv.org/abs/1505.04597). \n",
    "\n",
    "Here we will train a 3D U-Net model with the library [NNUNet](https://github.com/MIC-DKFZ/nnUNet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Install nnunet-v2 in the environment\n",
    "!pip install nnunetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting env variables for nnU-Net\n",
    "import os\n",
    "working_dir = os.getcwd()\n",
    "print(f\"The working directory is : {working_dir}\")\n",
    "os.environ['nnUNet_raw'] = f\"{working_dir}/nnunet_v2/nnUNet_raw/\"\n",
    "os.environ['nnUNet_preprocessed'] = f\"{working_dir}/nnunet_v2/nnUNet_preprocessed/\"\n",
    "os.environ['nnUNet_results'] = f\"{working_dir}/nnunet_v2/nnUNet_results/\"\n",
    "\n",
    "# testing if the variable has been saved\n",
    "print(os.environ[\"nnUNet_raw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing dataset before training\n",
    "\n",
    "!nnUNetv2_plan_and_preprocess -d 1 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begining Training model:\n",
    "!nnUNetv2_train -device cpu 1 3d_fullres all\n",
    "\n",
    "# You can use a lot of arguments. Here is used:\n",
    "#  - -device : choose if you want to train your model on the CPU or the GPU (if available)\n",
    "#  - \"1\" is the dataset code (here referring to \"Dataset001_BrainTumour\")\n",
    "#  - 3d_fullres : the configuration for the training, here we use a 3D U-Net \n",
    "#  - all : wether you wan't to train the model on all training data or if you want to cross validate (you will need to replace 'all' with [1 2 3 4 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
