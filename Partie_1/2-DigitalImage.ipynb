{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Digital Image Processing\n",
    "\n",
    "Image processing is the science of manipulating digital images with computer means. \n",
    "\n",
    "This includes methods and algorithms to **modify** an image (resizing, filtering, registration…), **improve the visual quality** of an image (deblurring, denoising…) or **analyze the information** contained in an image (Fourier analysis, contour detection…), among other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhFp6sxJSaH_"
   },
   "source": [
    "# Part1 - What is a digital image?\n",
    "A digital image is a visual representation of a numerical array that measures a physical phenomenon. Consequently, a digital image can be seen as an array of numbers, called *pixels*, on which mathematical operations could be performed.  \n",
    "\n",
    "Each pixel is characterized by:\n",
    "\n",
    "* its **position** in the image (row $i$ then column $j$, by convention)\n",
    "* and a **vector** containing as many values as the image has channels (also known as components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The array is not limited to two dimensions: it can have many dimensions depending of the type of image acquisition\n",
    "* There are many different digital **image formats** (e.g. `jpeg`, `png`, `bmp`, or `tiff` formats)\n",
    "* Acquisition devices are never perfect and introduce various modifications to the image, such as subsampling, quantization, noise, etc. Then we see how to display an image (remember: an array of numbers) into a visual representation, especially the relationship between the numbers and colors. \n",
    "* Finally, we introduce some very simple processings with arithmetic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a **grayscale image**, the vector representing the pixel has only one component so it is referred to as a monochrome (one-color) image. It contains gray-level information, no color information. The number of bits used for each pixel determines the number of different gray levels available. The typical grayscale image contains $8$ bits/pixels data, which allows to have $256$ different gray levels. The figures below shows an example of grayscale images.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/digitalimage2.png\" width=800 />\n",
    "</center>\n",
    "\n",
    "In applications like medical imaging ans astronomy, $12$ or $16$ bits/pixel images are used. These extra gray levels become useful when a small section of the image is made much larger to discern details.\n",
    "\n",
    "\n",
    "**Color images** can be modeled as three-band mononchrome image data, where each band of data corresponds to a different color. The actual information stored in the digital image data is the gray-level information in each spectral band.\n",
    "\n",
    "Typical color images are represented as red, green, and blue (RGB) images. Using the 8-bit monochrome standard as a model, the corresponding color image would have $24$ bits/pixel (8-bits for each of the three color bands red, green, and blue). The figure below illustrates a representation of a typical RGB color image.\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/Pixel.jpg\" width=600 />\n",
    "</center>\n",
    "\n",
    "Using the principle of additive synthesis, these light channels are superimposed to obtain the other colors (more on this in the next section). The array of pixels can be represented as a three-dimensional array (whose depth represents the number of spectral channels). In this case, a pixel is a three-component vector $p=(r_p,g_p,r_b)$ where:  \n",
    "\n",
    "* $r_p$  quantifies the red light intensity of pixel $p$,\n",
    "* $g_p$  quantifies the green light intensity of pixel $p$,\n",
    "* $b_p$  quantifies the blue light intensity of pixel $p$,\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/2d-arrays1.png\" width=\"270\" />\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/2d-arrays2.png\" width=\"300\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Digital image file formats\n",
    "\n",
    "Types of image data are divided in two primary categories: bitmap and vector.\n",
    "* **Bitmap images** (also called raster images) can be represented as 2-dimensional functions $f(x,y)$, where they have pixel data and the corresponding gray-level values stored in some file format\n",
    "* **Vector images** refer to methods of representing lines, curves, and shapes by storing only the key points. These key points are sufficient to define the shapes. The process of turning theses into an image is called rendering. After the image has been rendered, it can be thought of as being in bitmap format, where each pixel has specific values associated with it\n",
    "\n",
    "Mots of the types of file formats fall into the category of bitmap images, for example:\n",
    "* PPM (Portable Pix Map) format\n",
    "* TIFF (Tagged Image File Format)\n",
    "* GIF (Graphics Interchange Format)\n",
    "* JPEG (Joint Photographic Experts Group) format\n",
    "* BMP (Windows Bitmap)\n",
    "* PNG (Portable Network Graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image sampling and quantization \n",
    "\n",
    "In a mathematical view, a monochromatic image is a two-dimensional function $f(x,y)$, where $x$ and $y$ are spatial (plane) coordinates, and the aplitude of $f$ at any pair of coordinates $(x,y)$ is called the intenisty or garu level of the images at that point.\n",
    "\n",
    "The values of a monochromatic image (i.e intensities) are said to span grayscale\n",
    "\n",
    "When $x$, $y$ and the amplitude value of $f$ are all finite, discrete quantities, the image is called a digital image.\n",
    "\n",
    "To convert the continuous function $f(x,y)$ to digital form, we need to sample the function in both coordinates and in amplitude.\n",
    "\n",
    "* Digitizing the coordinate values is called **digital sampling**\n",
    "* Digitizing the amplitude values is called **pixel quantization**\n",
    "\n",
    "The number of selected values in the sampling process is known as the image spatial resolution. This is simply the number of pixels relative to the given image area.\n",
    "\n",
    "The number of selected values in the quantization process is called the gray-level (color-level) resolution. This is expressed in terms of the number of bits allocated to color levels.\n",
    "\n",
    "The quality of a digitized image depends on the resolution parameters on both processes.\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/digitalimagesfigure1.jpg\" width=500>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digital image representation\n",
    "The monochrome digital image $f(x,y)$ resulted from sampling and quantization has finite dicrete coordinates (usually noted $(j,i)$) and intensities (gray levels). We shall use integers values for these dicrete coordinates but not necessarily for gray levels.\n",
    "\n",
    "Thus, a digital image can be represented as a 2-dimensional array (matrix) that has $M$ rows and $N$ columns.\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/cs0100-2.13pgrid.jpg\" width=600>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples**\n",
    "\n",
    "* In a grayscale image, encoded using floating-points values in the range $[0,1]$, \n",
    "    * a black pixel is represented by the real value $0.0$.\n",
    "    * a white pixel is represented by the real value $1.0$\n",
    "    * a light gray pixel by the value $0.75$ (for example)\n",
    "    * and a dark gray pixel by the value $0.25$ (for example)  \n",
    "    \n",
    "<br>\n",
    "\n",
    "* In a RGB-encoded color image, using triplets of floating-point values in the range $([0,1] \\times [0,1] \\times [0,1])$\n",
    "    * A black pixel is represented by the triplet $(0.0, 0.0, 0.0)$\n",
    "    * a white pixel is represented by the triplet $(1.0, 1.0, 1.0)$\n",
    "    * a red (primary) pixel by $(1.0, 0.0, 0.0)$\n",
    "    * an orange pixel by $(1.0, 0.52, 0.0)$, for example (meaning that the intensity of red light is 100%, that of green 52% and that of blue 0%).\n",
    "    \n",
    "So these pixels have the respective colors:\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/couleurs.png\" width=400><br>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/couleurs2.png\" width=400>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do it with Python\n",
    "\n",
    "The Python data structure typically used to represent a digital image is the [NumPy array](https://numpy.org/doc/stable/reference/generated/numpy.array.html).\n",
    "\n",
    "* A digital image is therefore a 2D array of pixels (seen as a matrix), whose coefficients (pixels) are typically floats between $0$ and $1$ or integers between $0$ and $255$.\n",
    "* A grayscale pixel is an integer between 0 and 255 (associated type `uint8`) or a float between 0 and 1 (associated type `float`)\n",
    "* A pixel in color is an array of integers or floats (one `float` per chromatic component)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Load the dependencies\n",
    "This section loads some required libraries used in this notebook.\n",
    "\n",
    "The use of the function `ccc` available in the submodule `bbb` of the module `aaa` writes `aaa.bbb.ccc`. We are sure you agree this is a bit long to write, that is why we usually rename the submodule to something shorter. Thus, the following instructions rename `numpy` to `np`, `skimage.io` to `io`, `skimage.color` to `color`, `matplotlib.pyplot` to `plt` and `plotly.express` as `px`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ0MafhgkTbK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scientific programming\n",
    "import numpy as np           \n",
    "\n",
    "# display   \n",
    "import matplotlib.pyplot as plt   \n",
    "!pip install plotly\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "# image processing\n",
    "!pip install scikit-image\n",
    "import skimage \n",
    "import skimage.io as io\n",
    "import skimage.color as color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os, glob, shutil, tempfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download and store image source examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN936CoXxH85",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests, os \n",
    "from zipfile import ZipFile\n",
    "def download(url, destination):\n",
    "    response = requests.get(url, verify=True)\n",
    "    open(destination, 'wb').write(response.content)\n",
    "\n",
    "download(\"https://filesender.renater.fr/download.php?token=d39d2ec6-936f-4612-a153-53740cd26c7b&files_ids=53603412\", \"./images.zip\")\n",
    "shutil.unpack_archive('./images.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a grayscale image\n",
    "\n",
    "A grayscale image is represented as a three-dimensional array of numbers of size $M\\times N$. \n",
    "\n",
    "Python makes it easy to create simple images. \n",
    "\n",
    "Let's begin with creating a 4-pixel ($2 \\times 2)$ image with the following gray levels:\n",
    "\n",
    "* top left pixel: $0.98$\n",
    "* top right pixel : $0.43$\n",
    "* bottom left pixel : $0.11$\n",
    "* bottom right pixel : $0.79$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a 2x2 grayscale image\n",
    "img = np.array([[0.98, 0.43],\n",
    "                [0.11, 0.79]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize an image (or any array), we can use the following statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the image\n",
    "plt.imshow(img,cmap=\"gray\",vmin=0.0, vmax=1.0)\n",
    "\n",
    "# Overlay the corresponding pixel values\n",
    "for y in range(img.shape[0]):\n",
    "    for x in range(img.shape[1]):\n",
    "        plt.text(y,x,str(img[x,y]),ha='center',va='center',size=12,color='b')\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a color image\n",
    "\n",
    "As previously mentioned, a color image $u$ is represented by three grayscale images $u = (u_r,u_g,u_b)$. Each of these three images represents the amount of red, green and blue in each pixel. This is known as an RGB representation (for red, green, blue).\n",
    "\n",
    "A color image is represented as a three-dimensional array of numbers of size $M\\times N\\times 3$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a 4-pixel ($2 \\times 2)$ image with the following RGB color levels:\n",
    "\n",
    "* top left pixel: $(0.98,.98, 0.06, 0.18)$\n",
    "* top right pixel : $(0.78, 0.29, 0.91)$\n",
    "* bottom left pixel : $(0.49, 0.51, 0.37)$\n",
    "* bottom right pixel : $(0.53, 0.81, 0.55)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = np.array([[[0.98, 0.06, 0.18], [0.78, 0.29, 0.91]],\n",
    "                [[0.49, 0.51, 0.37], [0.53, 0.81, 0.55]]])\n",
    "for y in range(img.shape[0]):\n",
    "    for x in range(img.shape[1]):\n",
    "        print(img[x,y])\n",
    "        plt.text(y,x,str(img[x,y]),ha='center',va='center',size=12,color='b')\n",
    "plt.imshow(img,cmap=\"gray\",vmin=0.0, vmax=1.0)\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load, read and display a saved image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEU7V-mag5sm"
   },
   "source": [
    "The scikit-image module features two functions: `imread` and `imsave` (in the `imageio` sub-module), which respectively :\n",
    "\n",
    "* read an image file (in various formats) and return the corresponding array\n",
    "* write an image file using the values contained in an array\n",
    "\n",
    "The `imread` function initializes an array variable of size  $height \\times width  \\times depth$.\n",
    "\n",
    "$height$ and $width$ correspond to the dimensions, in pixels, of the loaded image ; $depth$, on the other hand, corresponds to the number of pixel components:\n",
    "\n",
    "* $1$ for luminance images (grayscale)\n",
    "* $3$ for color images (red, green, blue)\n",
    "* $4$ for color images with transparency (red, green, blue, alpha)\n",
    "\n",
    "Each component is a floating-point number in the range $[0,1]$.\n",
    "\n",
    "There's also an `imshow` function, which displays an image contained in an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Grayscale image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_gray = io.imread('./images/lena.png')\n",
    "io.imshow(img_gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Color image** \n",
    "\n",
    "I also take this opportunity to add a title and a suptitle to the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "x_CHRpIshQiN",
    "outputId": "2ae74b69-c638-491b-acf5-ce3856a6bb6e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_color = io.imread('./images/skin.jpg')\n",
    "plt.suptitle('Microscopy image of dermis and epidermis (skin layers)')\n",
    "plt.title('Hematoxylin and eosin stained slide at 10x of normal epidermis\\n and dermis with a benign intradermal nevus',fontstyle='italic',fontsize=10)\n",
    "io.imshow(img_color);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Image dimensions**\n",
    "\n",
    "The `shape` attribute lets us know the dimensions of the image as an `n-tuple` `(height, width, depth)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Dimensions of the two images above:\")\n",
    "print(img_gray.shape)\n",
    "print(img_color.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the height of image \n",
    "height = img_color.shape[0]\n",
    "# Check the width of image \n",
    "width = img_color.shape[1]\n",
    "# Check the number of channels of the image\n",
    "depth = img_color.shape[2]\n",
    "\n",
    "print(height,width,depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNr6zHSIkTb6"
   },
   "source": [
    "The two images above are NumPy arrays of integers between 0 and 255. This can be verified with the following statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uKjwTqIkTb7",
    "outputId": "d1759ba1-2591-463e-dff9-4998b91981f5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Min et max of the two images above:\")\n",
    "print(np.min(img_gray), np.max(img_gray))\n",
    "print(np.min(img_color), np.max(img_color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Image matrix data type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the image matrix data type (could know the bit depth of the image)\n",
    "print(\"Matrix data type of the two images above:\")\n",
    "print(img_gray.dtype)\n",
    "print(img_color.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_gray_float = (img_gray/255.).astype(np.float64)\n",
    "print(img_gray_float.dtype)\n",
    "print(np.min(img_gray_float), np.max(img_gray_float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `uint8` stands for 8-bit images (pixel values stored using 8-bit unsigned integers ranging from $0$ to $255$)\n",
    "* `float64` stands for floating-point images (pixel values stored using floating-point numbers ranging from $0$ to $1$)\n",
    "\n",
    "The data type of an image controls the range of possible intensities. As the number of possible values increases, the amount of space the image takes up in memory also increases.\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/types.png\" width=400>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Read and assign pixel values**\n",
    "\n",
    "Read and write access to the pixel located in the $i-th$ row and $j-th$ column of the image - i.e., with coordinates $(j,i)$ - is performed using $img[i,j]$. The first index corresponds to the y-coordinate (height, i.e. number of rows) and the second to the x-coordinate (width, i.e. number of columns).\n",
    "\n",
    "The pixel in the top left-hand corner of the image has coordinates $(0,0)$, with the x-axis horizontal to the right and the y-axis vertical to the bottom. The pixel in the bottom right-hand corner of the image has coordinates $(width-1,height-1)$.\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/imagenum.svg\" width=400>\n",
    "</center>\n",
    "\n",
    "**Note**: Python uses **zero-based indexing**. The first item in the array is assigned the index $0$. The second item is assigned the index $1$, the third is assigned the index $2$, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the pixel located in row $78$ and column $95$ of the previous image corresponds to the triplet $[216,221,227]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = img_color[78,95]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R, G and B components of this pixel $p$ are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Red: \", p[0])\n",
    "print(\"Green: \", p[1])\n",
    "print(\"Blue: \", p[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We can of course access a pixel component directly by specifying its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_color[78, 95 ,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax `array[a:b,c:d]` extract pixels located between rows $a$ and $b–1$ and columns $c$ and $d–1$. If $a$ or $c$ is not given, then it is considered to be $0$. If $b$ or $d$ is not given, then it is considered to be the maximal index in the dimension.\n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/extract.svg\" width=450>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can extract the intensities of the five first pixels of the second row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_gray[1,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the intensities of all the pixels in the third row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_gray[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using such a syntax, we can modify either a grayscale or color image by assigning new values to defined pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = np.copy(img_gray)\n",
    "img[200:300,200:300] = 0\n",
    "io.imshow(img, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img2 = np.copy(img_color)\n",
    "img2[300:400,200:300,:] = 0\n",
    "io.imshow(img2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save an image to file\n",
    "\n",
    "To write an array to a file, we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjI9aLVmkTcA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "io.imsave(\"./images/nouvelle_image.png\", img)\n",
    "img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRLYNFBQkTcD"
   },
   "source": [
    "**Note:** We recommand you to leave images in `uint8` between $0$ and $255$ before saving them with `imageio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To go further (before moving on to the rest of the course) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualization in 3D\n",
    "Visualizing three dimensional image data on a flat computer screen is challenging, especially when working with scripting languages such as Python. In this part, we will reintroduce the concepts of **slicing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-dimensional image stacks\n",
    "\n",
    "Multi-dimensionsal image data data can be handled in a similar way as multi-channel image data. For instance, three-dimensional image stacks are images with three spatial dimensions: X, Y, and Z. We find typical examples in microscopy and in medical imaging. \n",
    "\n",
    "<center>\n",
    "<img src=\"/files/TD-traitement-imageries-medicales/assets/CMMM2015-450341.002.jpg\" width=450>\n",
    "</center>\n",
    "\n",
    "Let’s take a look at an Magnetic Resonance Imaging (MRI) data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "image_stack = imread('./images/Haase_MRT_tfl3d1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data has indeed three dimensions, in this case 192 Z-planes and 256 X and Y in-plane pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image slicing\n",
    "\n",
    "We can inspect individual image slices by specifying their index in our 3D numpy array and this time use Matplotlib’s `imshow` function for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12,12))\n",
    "\n",
    "# show three planar images\n",
    "axs[0].imshow(image_stack[48], cmap='Greys_r')\n",
    "axs[1].imshow(image_stack[96], cmap='Greys_r')\n",
    "axs[2].imshow(image_stack[144], cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all three dimensions are spatial dimensions, we can also make slices orthogonal to the image plane and corresponding to anatomical planes. To orient the images correctly, we can transpose their axes by adding `.T` by the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coronal = image_stack[:,:,128].T\n",
    "axial = image_stack[:,128,:].T\n",
    "sagittal = image_stack[92]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12,12))\n",
    "\n",
    "# show orthogonal planes\n",
    "axs[0].imshow(coronal, cmap='Greys_r')\n",
    "axs[0].set_title('Coronal (frontal) view')\n",
    "\n",
    "axs[1].imshow(axial, cmap='Greys_r')\n",
    "axs[1].set_title('Axial (transverse) view')\n",
    "\n",
    "axs[2].imshow(sagittal, cmap='Greys_r')\n",
    "axs[2].set_title('Sagittal (longitudinal) view');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can create an plotly animation with slider that cycles through MRI Z-planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpXKoWeYuOf6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(\n",
    "    image_stack,\n",
    "    animation_frame=0,\n",
    "    color_continuous_scale='Greys_r',\n",
    "    labels=dict(animation_frame=\"slice\"),\n",
    "   height=400)\n",
    "fig.update_layout(coloraxis_showscale=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DICOM to NIfTI conversion\n",
    "\n",
    "PACS servers are an essential component of a type of clinical IT system called PACS – Picture Archiving and Communication System. The hardware and software components of PACS acquire digital images from PACS imaging modalities (such as ultrasound, CT, MRI, and radiography), store them into the **DICOM** (Digital Imaging and Communications in Medicine) file format, and transfer them to workstations where they can be accessed and reviewed.\n",
    "\n",
    "Many frameworks for medical image analysis may require a specific format such as **NIfTI** (Neuroimaging Informatics Technology Initiative). However, for the reason stated above, the raw data from scanners is often in DICOM format, so it needs to be first converted to the appropriate format to facilitate its utilization. \n",
    "\n",
    "We are going to write a simple script that uses the Python library dicom2nifti to demonstrate how to convert DICOM format to NIfTI format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Dataset**\n",
    "\n",
    "The data used is an MRI (Magnetic Resonance Imaging) DICOM data set of the head of a normal male human aged 52.\n",
    "\n",
    "The DICOM images correspond to a series of 2D slices, each representing a cross-sectional view of the head of that person. These slices are then organized in a specific order to reconstruct the entire 3D volume of the head. The NIfTI format is a common way to store and represent such 3D medical imaging data, where each slice is an integral part of the overall volume.\n",
    "\n",
    "**2. Conversion script**\n",
    "\n",
    "The function `dcm2nii` below will convert DICOM files from a directory to NIfTI format and save the resulting file in a specified output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install dicom2nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dicom2nifti\n",
    "\n",
    "def dcm2nii(MRI_dcm_path, nii_out_path):\n",
    "\n",
    "    '''\n",
    "    - MRI_dcm_path: Path to the directory containing MRI DICOM files\n",
    "    - nii_out_path: Path to the directory where the resulting NIfTI file will be saved.\n",
    "    - tempfile.TemporaryDirectory() to create a temporary directory (tmp) that will be automatically\n",
    "      deleted when the block of code inside it finishes execution\n",
    "    - dicom2nifti.convert_directory: convert the DICOM file to NIfTI format.\n",
    "    '''\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        tmp = Path(str(tmp))\n",
    "\n",
    "        # convert dicom directory to nifti\n",
    "        dicom2nifti.convert_directory(MRI_dcm_path, str(tmp),\n",
    "                                      compression=True, reorient=True)\n",
    "\n",
    "        #looks for the first NIfTI file (*nii.gz) in temp\n",
    "        nii = next(tmp.glob('*nii.gz'))\n",
    "\n",
    "        # copy nifti file to the specified output path and named it 'MRI.nii.gz'\n",
    "        shutil.copy(nii, nii_out_path+'MRI.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shutil.unpack_archive('./images/DICOM.zip', './images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nii_out_path = './images/'\n",
    "\n",
    "path_to_data =  './images/DICOM/ST000000/SE000001'\n",
    "\n",
    "dcm2nii(path_to_data, nii_out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Read and plot slices from the converted file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install SimpleITK\n",
    "path = \"./images/MRI.nii.gz\"\n",
    "MRI_nii = io.imread(path,plugin='simpleitk')\n",
    "\n",
    "print(MRI_nii.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape `(27, 256, 256)` refers respectively to the number of slices, height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize some slices (starting from the 5th one)\n",
    "def plot(no_):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    for i in range(1,no_+1):\n",
    "        plt.subplot(1,no_,i)\n",
    "        plt.imshow(MRI_nii[5+i,:,:].T,cmap='Greys_r')\n",
    "        plt.axis(\"off\")\n",
    "        plt.suptitle('Visualization of some MRI slices',y=0.6)\n",
    "\n",
    "    plt.show\n",
    "\n",
    "plot(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(\n",
    "    MRI_nii,\n",
    "    animation_frame=0,\n",
    "    color_continuous_scale='Greys_r',\n",
    "    labels=dict(animation_frame=\"slice\"),\n",
    "   height=400)\n",
    "fig.update_layout(coloraxis_showscale=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NiBabel](https://nipy.org/nibabel/gettingstarted.html) is a Python package for reading and writing neuroimaging data. To learn more about how NiBabel handles NIfTIs, check out the [Working with NIfTI images](https://nipy.org/nibabel/nifti_images.html) page of the NiBabel documentation, from which this episode is heavily based.\n",
    "\n",
    "First, use the `load()` function to create a NiBabel image object from a NIfTI file. We’ll load in an example MR image from the zip file we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "mri_nii = nib.load('./images/MRI.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Header**\n",
    "\n",
    "The header contains useful information that gives us information about the properties (metadata) associated with the MR data we’ve loaded in, such as image dimensions, data type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get the image header\n",
    "mri_hdr = mri_nii.header\n",
    "print(mri_hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pixel data**\n",
    "\n",
    "Now we’ll move in to loading the actual image data itself. We can achieve this by using the method called `get_fdata()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get the pixel data\n",
    "mri_data = mri_nii.get_fdata()\n",
    "print(mri_data.shape)\n",
    "print(type(mri_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a multidimensional array representing the image data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mri_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in the array (or voxel) is a floating-point number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize some slices (starting from the 5th one)\n",
    "def plot(no_):\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    for i in range(1,no_+1):\n",
    "        plt.subplot(1,no_,i)\n",
    "        plt.imshow(mri_data[:,:,5+i],cmap='Greys_r')\n",
    "        plt.axis(\"off\")\n",
    "        plt.suptitle('Visualization of some MRI slices',y=0.6)\n",
    "\n",
    "    plt.show\n",
    "\n",
    "plot(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Histogram of color image and grayscale image\n",
    "\n",
    "Histogram is one of the simplest tool for image processing. Histograms can be seen on cameras and even some smartphone, when shooting. Histogram is a graphical representation of the **intensity distribution** in a digital image. It plots the number of pixels for each intensity: the horizontal axis represents the intensities and the vertical axis represents the number of pixels in each intensity. \n",
    "\n",
    "The histogram of a digital image depicts how the intensities of its pixels are distributed. It is the discrete function such that:\n",
    "\n",
    "$$h(i)=n_i$$ where $n_i$ is the number of pixels with intensity $i$.\n",
    "\n",
    "The code below shows a color image and associated two histograms using the `matplot.pyplot hist()` function. The histograms are displayed as a bar plot, constituted as a set of bins. The number (hence the width) of the bins are chosen by the user; in the example below, we choose $256$ bins. Both histograms lie on $[0,255]$ which is the intensity range of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_color = io.imread('./images/ihc.png')\n",
    "plt.imshow(img_color)\n",
    "print(f\"Min: {img_color.min()}\")\n",
    "print(f\"Max: {img_color.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_color[:,:,2],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of all the pixels in the color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(img_color.ravel(), bins=256, range=(0,256));\n",
    "plt.xlim([0,256])\n",
    "plt.xlabel('Intensities')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.title('Histogram of the color image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of R, G, B channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color = ('r','g','b')\n",
    "for i,col in enumerate(color):\n",
    "    hist,_ = np.histogram(img_color[:,:,i].ravel(), bins=256, range=(0,256))\n",
    "    plt.plot(hist,color = col,  label=color[i].upper())\n",
    "    plt.legend()\n",
    "    plt.xlim([0,256])\n",
    "plt.xlabel('Intensities')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.title('Histogram of R, G, B channels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of all the pixels in the image after its grayscale conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_gray = skimage.color.rgb2gray(img_color)\n",
    "plt.imshow(img_gray, cmap=plt.cm.gray)\n",
    "print(f\"Min : {img_gray.min()}\")\n",
    "print(f\"Max : {img_gray.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(img_gray.ravel(), bins=256, range=(0,1));\n",
    "plt.xlim([0,1])\n",
    "plt.xlabel('Intensities')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.title ('Histogram after grayscale conversion');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish two “modes” on the histogram. \n",
    "\n",
    "* The one on the left (intensities less than $0.7$) corresponds to the darker tones in the image (immunohistochemical and hematoxylin stainings). \n",
    "* The one on the right (intensities more than $0.8$) corresponds to the light tones (background)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some remarks**\n",
    "\n",
    "* If the histogram is normalized (i.e. the bins are divided by the pixel number $M \\times N$), then it can be seen as a discrete probability density function $p$: \n",
    "\n",
    "$$p(i)=\\frac{n_i}{M \\times N}$$\n",
    "\n",
    "* The histogram gives a global information about the pixel intensities of an image but looses the spatial information in the image. In consequence, two different images can have the same histogram. \n",
    "\n",
    "For example, the following two images have the same histogram (the image on the right actually corresponds to the pixels of the image on the left sorted with respect to their gray level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = np.sort(img_gray.ravel())\n",
    "\n",
    "plt.subplots(2,2,figsize=(8,6))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img_gray,cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(222)\n",
    "plt.imshow(img.reshape(img_gray.shape[0],img_gray.shape[1]),cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(223)\n",
    "plt.hist(img_gray.ravel(), bins=256, range=(0,1));\n",
    "plt.xlim([0,1])\n",
    "plt.subplot(224)\n",
    "plt.hist(img.reshape(img_gray.shape[0],img_gray.shape[1]).ravel(), bins=256, range=(0,1));\n",
    "plt.xlim([0,1])\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
